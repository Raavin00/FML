{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmTvMqn/32MGHBvSe5UFGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raavin00/FML/blob/main/Tokennization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization using Pythons split() function"
      ],
      "metadata": {
        "id": "TN1z_FeLT4er"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBkS_HsRRcg1",
        "outputId": "8e52b692-a6b7-4877-e704-c604317e016c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once', 'there', 'was', 'a', 'boy', 'named', 'Rocky', '.', 'He', 'always', 'wanted', 'to', 'do', 'crazy', 'things', 'which', 'makes', 'people', 'irritate.']\n",
            "No of Tokens 19\n"
          ]
        }
      ],
      "source": [
        "text = \"Once there was a boy named  Rocky . He always wanted to do crazy things which makes people irritate.\"\n",
        "tokens=text.split()\n",
        "print(tokens)\n",
        "print(\"No of Tokens\",len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Once there was a boy named  Rocky . He always wanted to do crazy things which makes people irritate.\"\n",
        "sentences = text.split('.')\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhuHsf44To0R",
        "outputId": "ba44ee47-fc61-4208-d030-b692cc70121b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once there was a boy named  Rocky ', ' He always wanted to do crazy things which makes people irritate', '']\n",
            "No.of sentences :  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization using Regular Expressions\n",
        "\n",
        "import re\n",
        "tokens=re.findall(\"[\\w']+\",text)\n",
        "print(tokens)\n",
        "print(\"No of Tokens :\",len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RbTn0JYUVAU",
        "outputId": "f0fc6347-43d9-445f-a6e8-bf3fa04530b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once', 'there', 'was', 'a', 'boy', 'named', 'Rocky', 'He', 'always', 'wanted', 'to', 'do', 'crazy', 'things', 'which', 'makes', 'people', 'irritate']\n",
            "No of Tokens : 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = re.compile('[.?!] ').split(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B5WLJ-3VVpZ",
        "outputId": "60dd4057-b94f-4609-84a0-5bd6840c3141"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once there was a boy named  Rocky ', 'He always wanted to do crazy things which makes people irritate.']\n",
            "No.of sentences :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization using NLTK\n",
        "\n",
        "\n",
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3cT0FGV8c9",
        "outputId": "28313707-0996-4404-a1eb-95c3ed9be4fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M_jk3riWNNb",
        "outputId": "ebf35681-b0e8-4a1b-94db-1f46d7b97e4a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Tokenization\n",
        "from nltk.tokenize import word_tokenize \n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXz7HqL-WYwa",
        "outputId": "b9545335-aa2f-4c72-98e4-add5ee9ea3b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once', 'there', 'was', 'a', 'boy', 'named', 'Rocky', '.', 'He', 'always', 'wanted', 'to', 'do', 'crazy', 'things', 'which', 'makes', 'people', 'irritate', '.']\n",
            "No.of tokens :  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lClaP111WjQw",
        "outputId": "ddd3d564-e4e5-40ec-bcb8-1614eca2bf06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once there was a boy named  Rocky .', 'He always wanted to do crazy things which makes people irritate.']\n",
            "No.of sentences :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming words\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "VUClu2XWWnTY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"cats\"))\n",
        "print(porter.stem(\"troubling\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiz1FwNqXDwP",
        "outputId": "f7e155fc-cbc0-4791-8eb6-501aef5c514a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "troubl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    print(token_words)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "x=stemSentence(sentence)\n",
        "print(\"Sentence after stemming :\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI6uYfv9XGkl",
        "outputId": "0c3c9bb2-b2c2-4107-8959-a0f26c04a2d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pythoners', 'are', 'very', 'intelligent', 'and', 'work', 'very', 'pythonly', 'and', 'now', 'they', 'are', 'pythoning', 'their', 'way', 'to', 'success', '.']\n",
            "Sentence after stemming : python are veri intellig and work veri pythonli and now they are python their way to success . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "token_words = nltk.word_tokenize(sentence)\n",
        "print(token_words)\n",
        "\n",
        "lemma_sentence=[]\n",
        "for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\" \")\n",
        "\n",
        "print(\"lemmas of tokens: \", ''.join(lemma_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_UmW1I3XPeE",
        "outputId": "1ebe5787-6b14-4012-88cc-56a6b25128c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'was', 'running', 'and', 'eating', 'at', 'same', 'time', '.', 'He', 'has', 'bad', 'habit', 'of', 'swimming', 'after', 'playing', 'long', 'hours', 'in', 'the', 'Sun', '.']\n",
            "lemmas of tokens:  He wa running and eating at same time . He ha bad habit of swimming after playing long hour in the Sun . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdr0s4VxXb_b",
        "outputId": "1018e000-ef96-42b5-a288-21a9249a2fc7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}